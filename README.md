# ğŸ§  ASL Sign Language Recognition System

A deep learning-based ASL Sign Language Recognition System that uses a CNN model to identify hand signs from images. Includes a simple UI for real-time predictions and supports image uploads for classification.

---

## ğŸ“‘ Table of Contents

- [About the Project](#-about-the-project)
- [Tech Stack](#-tech-stack)
- [Features](#-features)
- [Repo Structure](#-repo-structure)
- [Kaggle Database](#-kaggle-database)
- [Setup Instructions](#-setup-instructions)
- [How It Works](#-how-it-works)
- [Screenshots](#-screenshots)
- [Future Enhancements](#-future-enhancements)
- [Contact](#-contact)

---

## ğŸ“˜ About the Project

This project is designed to recognize American Sign Language (ASL) alphabets using a trained Convolutional Neural Network (CNN). Users can upload hand sign images via an interface and get real-time predictions.

---

## ğŸ§° Tech Stack

- Python
- TensorFlow / Keras
- OpenCV
- Streamlit
- scikit-learn / joblib

---

## âœ¨ Features

- ASL hand sign classification (Aâ€“Z)
- Real-time prediction via web interface
- CNN model trained on Kaggle dataset
- Lightweight and easy to run locally

---

## ğŸ“‚ Repo Structure

.<br>
â”œâ”€â”€ app.py # Streamlit UI<br>
â”œâ”€â”€ asl.py # Prediction logic<br>
â”œâ”€â”€ cnn_asl.joblib # Trained CNN model<br>
â”œâ”€â”€ predict.png # Prediction image<br>
â”œâ”€â”€ ui.png # Streamlit UI<br>
â”œâ”€â”€ result.png # Model Training Results<br>
â”œâ”€â”€ README.md # Documentation<br>


---

## ğŸ“Š Kaggle Database

This project uses the publicly available [ASL Alphabet Dataset on Kaggle](https://www.kaggle.com/datasets/grassknoted/asl-alphabet).

Expected structure after download:

data/<br>
â”œâ”€â”€ train/<br>
â””â”€â”€ test/<br>


---

## âš™ï¸ Setup Instructions

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/asl-sign-language-recognition.git
   cd asl-sign-language-recognition
   ```

2. **Install dependencies:**

  ```bash
  pip install streamlit opencv-python joblib
  ```

3. **Run the app:**

  ```bash
     streamlit run app.py
  ```


## ğŸ§  How It Works

    The model was trained on ASL hand sign images (A-Z) using a CNN architecture.

    The model is saved as cnn_asl.joblib.

    Uploaded images are processed and classified using the trained model.

    Streamlit displays the result in a user-friendly format.

## ğŸ–¼ï¸ Screenshots

Training Results
![Training Results](result.png)

Streamlit UI
![Streamlit UI](ui.png)

Prediction on test image
![Prediction](predict.png)

## ğŸš§ Future Enhancements

    Add webcam support for live sign detection

    Expand model to include dynamic signs and gestures

    Improve model accuracy with data augmentation

    Host the app on the web using Streamlit Cloud or Hugging Face Spaces

## ğŸ“¬ Contact

Anij Mehta<br>
ğŸ”— [GitHub](https://github.com/anij-mehta)<br>
ğŸ”— [LinkedIn](https://www.linkedin.com/in/anij-mehta)
